{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extra_reprメソッドとその周辺"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "extra_reprメソッドは，nn.Moduleサブクラスのインスタンスをprintした際に表示される文字列を設定するメソッドです．\\__str\\__や\\__repr\\__のように一般的なPythonクラスに用意された特殊メソッドではなく，nn.Module独自のメソッドになります．\n",
    "\n",
    "- `extra_repr`メソッド\n",
    "    - クラスの名前や内部のパラメータの形状などを出力させます．\n",
    "- `__str__`メソッド\n",
    "    - 人間にとってわかりやすく，画面に表示しやすいオブジェクトの表現を出力させます．（した方がいいです）\n",
    "- `__repr__`メソッド\n",
    "    - eval関数で評価すると元のオブジェクトに戻るような，Pythonが元のオブジェクトを復元できるオブジェクト表現を出力させます．（した方がいいです）"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 自作クラスとオブジェクトid"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "何の設定もしていない自作クラスがどのように表示されるかを見てみましょう：  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "普通にprintした時に表示されるもの:\t <__main__.temp object at 0x104e7b370>\n",
      "オブジェクトのid:\t\t\t 4377260912\n",
      "オブジェクトのidを16進数にしたもの:\t 0x104e7b370\n"
     ]
    }
   ],
   "source": [
    "class temp:\n",
    "    ...\n",
    "\n",
    "obj = temp()\n",
    "\n",
    "print(\"普通にprintした時に表示されるもの:\\t\",obj)\n",
    "print(\"オブジェクトのid:\\t\\t\\t\",id(obj))\n",
    "print(\"オブジェクトのidを16進数にしたもの:\\t\", hex(id(obj)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "特に何の設定もしていない自作クラスをprintすると，オブジェクトのid（識別子）が16進数で表示されるようです．また，おそらく皆さんはCPythonを利用しているはずなので，このオブジェクトidにはメモリアドレスが利用されています．（id関数のdocstringを読んでみてください）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m/\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "Return the identity of an object.\n",
      "\n",
      "This is guaranteed to be unique among simultaneously existing objects.\n",
      "(CPython uses the object's memory address.)\n",
      "\u001b[0;31mType:\u001b[0m      builtin_function_or_method"
     ]
    }
   ],
   "source": [
    "id?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> これは同時に存在するオブジェクトの中で一意であることが保証されています。(CPythonはオブジェクトのメモリアドレスを使います)。\n",
    "\n",
    "逆説的に，CPython以外のPython実装では，オブジェクトidがメモリアドレスだとは限らないことに注意です．"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### extra_reprの設定"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[nn.Linearクラスの実装](https://pytorch.org/docs/stable/_modules/torch/nn/modules/linear.html#Linear)を参考にextra_reprの書き方を覚えてください．"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "class Linear(Module):\n",
    "    r\"\"\"Applies a linear transformation to the incoming data: :math:`y = xA^T + b`\n",
    "\n",
    "    This module supports :ref:`TensorFloat32<tf32_on_ampere>`.\n",
    "\n",
    "    On certain ROCm devices, when using float16 inputs this module will use :ref:`different precision<fp16_on_mi200>` for backward.\n",
    "\n",
    "    Args:\n",
    "        in_features: size of each input sample\n",
    "        out_features: size of each output sample\n",
    "        bias: If set to ``False``, the layer will not learn an additive bias.\n",
    "            Default: ``True``\n",
    "\n",
    "    Shape:\n",
    "        - Input: :math:`(*, H_{in})` where :math:`*` means any number of\n",
    "          dimensions including none and :math:`H_{in} = \\text{in\\_features}`.\n",
    "        - Output: :math:`(*, H_{out})` where all but the last dimension\n",
    "          are the same shape as the input and :math:`H_{out} = \\text{out\\_features}`.\n",
    "\n",
    "    Attributes:\n",
    "        weight: the learnable weights of the module of shape\n",
    "            :math:`(\\text{out\\_features}, \\text{in\\_features})`. The values are\n",
    "            initialized from :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})`, where\n",
    "            :math:`k = \\frac{1}{\\text{in\\_features}}`\n",
    "        bias:   the learnable bias of the module of shape :math:`(\\text{out\\_features})`.\n",
    "                If :attr:`bias` is ``True``, the values are initialized from\n",
    "                :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})` where\n",
    "                :math:`k = \\frac{1}{\\text{in\\_features}}`\n",
    "\n",
    "    Examples::\n",
    "\n",
    "        >>> m = nn.Linear(20, 30)\n",
    "        >>> input = torch.randn(128, 20)\n",
    "        >>> output = m(input)\n",
    "        >>> print(output.size())\n",
    "        torch.Size([128, 30])\n",
    "    \"\"\"\n",
    "    __constants__ = ['in_features', 'out_features']\n",
    "    in_features: int\n",
    "    out_features: int\n",
    "    weight: Tensor\n",
    "\n",
    "    def __init__(self, in_features: int, out_features: int, bias: bool = True,\n",
    "                 device=None, dtype=None) -> None:\n",
    "        factory_kwargs = {'device': device, 'dtype': dtype}\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weight = Parameter(torch.empty((out_features, in_features), **factory_kwargs))\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.empty(out_features, **factory_kwargs))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self) -> None:\n",
    "        # Setting a=sqrt(5) in kaiming_uniform is the same as initializing with\n",
    "        # uniform(-1/sqrt(in_features), 1/sqrt(in_features)). For details, see\n",
    "        # https://github.com/pytorch/pytorch/issues/57109\n",
    "        init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n",
    "        if self.bias is not None:\n",
    "            fan_in, _ = init._calculate_fan_in_and_fan_out(self.weight)\n",
    "            bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n",
    "            init.uniform_(self.bias, -bound, bound)\n",
    "\n",
    "    def forward(self, input: Tensor) -> Tensor:\n",
    "        return F.linear(input, self.weight, self.bias)\n",
    "\n",
    "    def extra_repr(self) -> str:\n",
    "        return 'in_features={}, out_features={}, bias={}'.format(\n",
    "            self.in_features, self.out_features, self.bias is not None\n",
    "        )\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datasci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
