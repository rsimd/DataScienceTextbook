{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Auto Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# packageのimport\n",
    "from typing import Any, Union, Callable, Type, TypeVar\n",
    "from tqdm.std import trange,tqdm\n",
    "import numpy as np \n",
    "import numpy.typing as npt\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import requests\n",
    "\n",
    "# pytorch関連のimport\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "import torch.optim as optim \n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import DataLoader\n",
    "from src.utils import set_seed\n",
    "from src.layers import Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 2023_6_27\n",
    "set_seed(SEED)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AutoEncoderに畳み込みレイヤを利用しよう"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNISTを学習する例ではデータ行列をflattenすることで通常のMLP構造のAEで画像データへ対応しました．AEで次元削減する対象は画像データだけではないですが，画像に対して利用する場合はやはり，畳み込みレイヤを利用するのが一般的です．"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今回はデータセットとしてCIFAR-10を利用します．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_data = torchvision.datasets.CIFAR10(\n",
    "    './data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform = T.Compose([T.ToTensor()]),\n",
    "    )\n",
    "test_data = torchvision.datasets.CIFAR10(\n",
    "    './data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform = T.Compose([T.ToTensor()]),\n",
    "    )\n",
    "\n",
    "train_loader = DataLoader(train_data, 64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----input-----\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "-----output-----\n",
      "torch.Size([64, 50])\n"
     ]
    }
   ],
   "source": [
    "encoder = nn.Sequential(\n",
    "    nn.Conv2d(3, 16, 3, 1, padding=1),\n",
    "    nn.BatchNorm2d(16),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2,2),\n",
    "    nn.Conv2d(16, 8, 3, 1, padding=1),\n",
    "    nn.BatchNorm2d(8),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2,2),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(8*8*8, 50),\n",
    "    nn.ReLU(),\n",
    ")\n",
    "print(\"-----input-----\")\n",
    "batch = next(iter(train_loader))\n",
    "x,y = batch\n",
    "print(x.shape)\n",
    "print(x.shape)\n",
    "\n",
    "print(\"-----output-----\")\n",
    "y = encoder(x)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 3, 8, 8])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder = nn.Sequential(\n",
    "    nn.Linear(50, 8*8*8),\n",
    "    nn.ReLU(),\n",
    "    Reshape((8,8,8)),\n",
    "    nn.ConvTranspose2d(8, 16, 3, 1, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.ConvTranspose2d(16, 3, 3, 1, padding=1),\n",
    "    nn.Sigmoid(),\n",
    ")\n",
    "decoder(y).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "convae = nn.Sequential(encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'skorch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[65], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mskorch\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'skorch'"
     ]
    }
   ],
   "source": [
    "import skorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datasci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
