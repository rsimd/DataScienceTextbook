Traceback (most recent call last):
  File "/Users/mriki/.pyenv/versions/miniforge3-4.10.3-10/envs/datasci/lib/python3.10/site-packages/jupyter_cache/executors/utils.py", line 58, in single_nb_execution
    executenb(
  File "/Users/mriki/.pyenv/versions/miniforge3-4.10.3-10/envs/datasci/lib/python3.10/site-packages/nbclient/client.py", line 1204, in execute
    return NotebookClient(nb=nb, resources=resources, km=km, **kwargs).execute()
  File "/Users/mriki/.pyenv/versions/miniforge3-4.10.3-10/envs/datasci/lib/python3.10/site-packages/nbclient/util.py", line 84, in wrapped
    return just_run(coro(*args, **kwargs))
  File "/Users/mriki/.pyenv/versions/miniforge3-4.10.3-10/envs/datasci/lib/python3.10/site-packages/nbclient/util.py", line 62, in just_run
    return loop.run_until_complete(coro)
  File "/Users/mriki/.pyenv/versions/miniforge3-4.10.3-10/envs/datasci/lib/python3.10/asyncio/base_events.py", line 646, in run_until_complete
    return future.result()
  File "/Users/mriki/.pyenv/versions/miniforge3-4.10.3-10/envs/datasci/lib/python3.10/site-packages/nbclient/client.py", line 663, in async_execute
    await self.async_execute_cell(
  File "/Users/mriki/.pyenv/versions/miniforge3-4.10.3-10/envs/datasci/lib/python3.10/site-packages/nbclient/client.py", line 965, in async_execute_cell
    await self._check_raise_for_error(cell, cell_index, exec_reply)
  File "/Users/mriki/.pyenv/versions/miniforge3-4.10.3-10/envs/datasci/lib/python3.10/site-packages/nbclient/client.py", line 862, in _check_raise_for_error
    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)
nbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:
------------------
trainer = NeuralNetRegressor(
    SkipGram(len(word2id), 50),
    optimizer=optim.Adam,
    criterion=BowCrossEntropy,
    max_epochs=20,
    batch_size=128,
    lr=0.01,
    callbacks=[
        EpochScoring(lambda net,X=None,y=None: np.exp(net.history_[-1, "valid_loss"]), name="valid_ppl"), 
        EpochScoring(lambda net,X=None,y=None: np.exp(net.history_[-1, "train_loss"]), name="train_ppl", on_train=True,)
    ],
    device="cpu", # é©å®œå¤‰æ›´
)

trainer.fit(target, contexts.toarray())
------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mValueError[0m                                Traceback (most recent call last)
Cell [0;32mIn[7], line 15[0m
[1;32m      1[0m trainer [38;5;241m=[39m NeuralNetRegressor(
[1;32m      2[0m     SkipGram([38;5;28mlen[39m(word2id), [38;5;241m50[39m),
[1;32m      3[0m     optimizer[38;5;241m=[39moptim[38;5;241m.[39mAdam,
[0;32m   (...)[0m
[1;32m     12[0m     device[38;5;241m=[39m[38;5;124m"[39m[38;5;124mcpu[39m[38;5;124m"[39m, [38;5;66;03m# é©å®œå¤‰æ›´[39;00m
[1;32m     13[0m )
[0;32m---> 15[0m [43mtrainer[49m[38;5;241;43m.[39;49m[43mfit[49m[43m([49m[43mtarget[49m[43m,[49m[43m [49m[43mcontexts[49m[38;5;241;43m.[39;49m[43mtoarray[49m[43m([49m[43m)[49m[43m)[49m

File [0;32m~/.pyenv/versions/miniforge3-4.10.3-10/envs/datasci/lib/python3.10/site-packages/skorch/regressor.py:82[0m, in [0;36mNeuralNetRegressor.fit[0;34m(self, X, y, **fit_params)[0m
[1;32m     71[0m [38;5;250m[39m[38;5;124;03m"""See ``NeuralNet.fit``.[39;00m
[1;32m     72[0m 
[1;32m     73[0m [38;5;124;03mIn contrast to ``NeuralNet.fit``, ``y`` is non-optional to[39;00m
[0;32m   (...)[0m
[1;32m     77[0m 
[1;32m     78[0m [38;5;124;03m"""[39;00m
[1;32m     79[0m [38;5;66;03m# pylint: disable=useless-super-delegation[39;00m
[1;32m     80[0m [38;5;66;03m# this is actually a pylint bug:[39;00m
[1;32m     81[0m [38;5;66;03m# https://github.com/PyCQA/pylint/issues/1085[39;00m
[0;32m---> 82[0m [38;5;28;01mreturn[39;00m [38;5;28;43msuper[39;49m[43m([49m[43mNeuralNetRegressor[49m[43m,[49m[43m [49m[38;5;28;43mself[39;49m[43m)[49m[38;5;241;43m.[39;49m[43mfit[49m[43m([49m[43mX[49m[43m,[49m[43m [49m[43my[49m[43m,[49m[43m [49m[38;5;241;43m*[39;49m[38;5;241;43m*[39;49m[43mfit_params[49m[43m)[49m

File [0;32m~/.pyenv/versions/miniforge3-4.10.3-10/envs/datasci/lib/python3.10/site-packages/skorch/net.py:1300[0m, in [0;36mNeuralNet.fit[0;34m(self, X, y, **fit_params)[0m
[1;32m   1268[0m [38;5;250m[39m[38;5;124;03m"""Initialize and fit the module.[39;00m
[1;32m   1269[0m 
[1;32m   1270[0m [38;5;124;03mIf the module was already initialized, by calling fit, the[39;00m
[0;32m   (...)[0m
[1;32m   1297[0m 
[1;32m   1298[0m [38;5;124;03m"""[39;00m
[1;32m   1299[0m [38;5;28;01mif[39;00m [38;5;129;01mnot[39;00m [38;5;28mself[39m[38;5;241m.[39mwarm_start [38;5;129;01mor[39;00m [38;5;129;01mnot[39;00m [38;5;28mself[39m[38;5;241m.[39minitialized_:
[0;32m-> 1300[0m     [38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43minitialize[49m[43m([49m[43m)[49m
[1;32m   1302[0m [38;5;28mself[39m[38;5;241m.[39mpartial_fit(X, y, [38;5;241m*[39m[38;5;241m*[39mfit_params)
[1;32m   1303[0m [38;5;28;01mreturn[39;00m [38;5;28mself[39m

File [0;32m~/.pyenv/versions/miniforge3-4.10.3-10/envs/datasci/lib/python3.10/site-packages/skorch/net.py:888[0m, in [0;36mNeuralNet.initialize[0;34m(self)[0m
[1;32m    886[0m [38;5;28mself[39m[38;5;241m.[39m_initialize_module()
[1;32m    887[0m [38;5;28mself[39m[38;5;241m.[39m_initialize_criterion()
[0;32m--> 888[0m [38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43m_initialize_optimizer[49m[43m([49m[43m)[49m
[1;32m    889[0m [38;5;28mself[39m[38;5;241m.[39m_initialize_history()
[1;32m    891[0m [38;5;28mself[39m[38;5;241m.[39m_validate_params()

File [0;32m~/.pyenv/versions/miniforge3-4.10.3-10/envs/datasci/lib/python3.10/site-packages/skorch/net.py:859[0m, in [0;36mNeuralNet._initialize_optimizer[0;34m(self, reason)[0m
[1;32m    856[0m         msg [38;5;241m=[39m [38;5;28mself[39m[38;5;241m.[39m_format_reinit_msg([38;5;124m"[39m[38;5;124moptimizer[39m[38;5;124m"[39m, triggered_directly[38;5;241m=[39m[38;5;28;01mFalse[39;00m)
[1;32m    857[0m     [38;5;28mprint[39m(msg)
[0;32m--> 859[0m [38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43minitialize_optimizer[49m[43m([49m[43m)[49m
[1;32m    861[0m [38;5;66;03m# register the virtual params for all optimizers[39;00m
[1;32m    862[0m [38;5;28;01mfor[39;00m name [38;5;129;01min[39;00m [38;5;28mself[39m[38;5;241m.[39m_optimizers:

File [0;32m~/.pyenv/versions/miniforge3-4.10.3-10/envs/datasci/lib/python3.10/site-packages/skorch/net.py:625[0m, in [0;36mNeuralNet.initialize_optimizer[0;34m(self, triggered_directly)[0m
[1;32m    621[0m args, kwargs [38;5;241m=[39m [38;5;28mself[39m[38;5;241m.[39mget_params_for_optimizer(
[1;32m    622[0m     [38;5;124m'[39m[38;5;124moptimizer[39m[38;5;124m'[39m, named_parameters)
[1;32m    624[0m [38;5;66;03m# pylint: disable=attribute-defined-outside-init[39;00m
[0;32m--> 625[0m [38;5;28mself[39m[38;5;241m.[39moptimizer_ [38;5;241m=[39m [38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43moptimizer[49m[43m([49m[38;5;241;43m*[39;49m[43margs[49m[43m,[49m[43m [49m[38;5;241;43m*[39;49m[38;5;241;43m*[39;49m[43mkwargs[49m[43m)[49m
[1;32m    626[0m [38;5;28;01mreturn[39;00m [38;5;28mself[39m

File [0;32m~/.pyenv/versions/miniforge3-4.10.3-10/envs/datasci/lib/python3.10/site-packages/torch/optim/adam.py:33[0m, in [0;36mAdam.__init__[0;34m(self, params, lr, betas, eps, weight_decay, amsgrad, foreach, maximize, capturable, differentiable, fused)[0m
[1;32m     27[0m     [38;5;28;01mraise[39;00m [38;5;167;01mValueError[39;00m([38;5;124m"[39m[38;5;124mInvalid weight_decay value: [39m[38;5;132;01m{}[39;00m[38;5;124m"[39m[38;5;241m.[39mformat(weight_decay))
[1;32m     29[0m defaults [38;5;241m=[39m [38;5;28mdict[39m(lr[38;5;241m=[39mlr, betas[38;5;241m=[39mbetas, eps[38;5;241m=[39meps,
[1;32m     30[0m                 weight_decay[38;5;241m=[39mweight_decay, amsgrad[38;5;241m=[39mamsgrad,
[1;32m     31[0m                 maximize[38;5;241m=[39mmaximize, foreach[38;5;241m=[39mforeach, capturable[38;5;241m=[39mcapturable,
[1;32m     32[0m                 differentiable[38;5;241m=[39mdifferentiable, fused[38;5;241m=[39mfused)
[0;32m---> 33[0m [38;5;28;43msuper[39;49m[43m([49m[43m)[49m[38;5;241;43m.[39;49m[38;5;21;43m__init__[39;49m[43m([49m[43mparams[49m[43m,[49m[43m [49m[43mdefaults[49m[43m)[49m
[1;32m     35[0m [38;5;28;01mif[39;00m fused:
[1;32m     36[0m     [38;5;28;01mif[39;00m differentiable:

File [0;32m~/.pyenv/versions/miniforge3-4.10.3-10/envs/datasci/lib/python3.10/site-packages/torch/optim/optimizer.py:187[0m, in [0;36mOptimizer.__init__[0;34m(self, params, defaults)[0m
[1;32m    185[0m param_groups [38;5;241m=[39m [38;5;28mlist[39m(params)
[1;32m    186[0m [38;5;28;01mif[39;00m [38;5;28mlen[39m(param_groups) [38;5;241m==[39m [38;5;241m0[39m:
[0;32m--> 187[0m     [38;5;28;01mraise[39;00m [38;5;167;01mValueError[39;00m([38;5;124m"[39m[38;5;124moptimizer got an empty parameter list[39m[38;5;124m"[39m)
[1;32m    188[0m [38;5;28;01mif[39;00m [38;5;129;01mnot[39;00m [38;5;28misinstance[39m(param_groups[[38;5;241m0[39m], [38;5;28mdict[39m):
[1;32m    189[0m     param_groups [38;5;241m=[39m [{[38;5;124m'[39m[38;5;124mparams[39m[38;5;124m'[39m: param_groups}]

[0;31mValueError[0m: optimizer got an empty parameter list
ValueError: optimizer got an empty parameter list

